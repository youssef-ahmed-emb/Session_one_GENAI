{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Ouput Parsers\n",
    "* Format the answer of the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721c4a4-56d6-48e2-b9db-0de0309c492a",
   "metadata": {},
   "source": [
    "## Parsing Outputs\n",
    "* See the corresponding LangChain Documentation page [here](https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/).\n",
    "* Language models output text. But sometimes we would like to have those answers in a different format, like a JSON dictionary or a XML document. In order to achieve that, we use the Output Parsers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177b19be-ea45-4ecb-a4dc-914da7958de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llmModel = OpenAI()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Return a JSON object with an `answer` key that answers the following question: {question}\"\n",
    ")\n",
    "\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "json_chain = prompt | llmModel | json_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb4ed2-f174-4177-b38d-b03397e4f2a7",
   "metadata": {},
   "source": [
    "#### The previous prompt template includes the parser instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "047f7986-5502-4205-9a7a-e7e7e26f51a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb755d4-4a0f-486a-99dd-ea1873eb7c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'What do you call a fake noodle? An Impasta.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_chain.invoke({\"question\": \"Tell me a joke\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1181d87-13df-4abf-9910-0b44618642de",
   "metadata": {},
   "source": [
    "#### Optionally, you can use Pydantic to define a custom output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdcf2860-9b94-46f9-94f8-81ce173b8ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Archived\\Session one\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3699: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "873de824-c105-4e36-b4a7-d4bb498efc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Pydantic Object with the desired output format.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a5c131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Define the parser referring the Pydantic Object\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7006219-e78f-4f1f-8d8a-559679f84845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'لماذا كان ستالين دائمًا يحمل خريطة معه؟',\n",
       " 'punchline': 'لأنه كان يحب أن يعرف أين يذهب لتوقيع البيعة!'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parser referring the Pydantic Object\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# Add the parser format instructions in the prompt definition.\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "ChatModel = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# Create a chain with the prompt and the parser\n",
    "chain = prompt | ChatModel | parser\n",
    "\n",
    "chain.invoke({\"query\": \"قولي نكته عن ستالين\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f487c7a",
   "metadata": {},
   "source": [
    "# Quicker revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a20c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05c64d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76eaa044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_no_chain(input):\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"Tell a story about {player} in 100 words\"\"\"\n",
    "    )\n",
    "\n",
    "    prompt = prompt.invoke(input)\n",
    "    \n",
    "    ChatModel = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    response = ChatModel.invoke(prompt)\n",
    "\n",
    "    OutputParser = StrOutputParser()\n",
    "    \n",
    "    response_parsed = OutputParser.invoke(response)\n",
    "    \n",
    "    print(f\"response parsed:\\n{response_parsed}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67f91ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def using_chain(input):\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"Tell a story about {player} in 100 words\"\"\"\n",
    "    )\n",
    "\n",
    "    ChatModel = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    chain = prompt | ChatModel | StrOutputParser()\n",
    "    \n",
    "    response = chain.invoke(input)\n",
    "    \n",
    "    print(f\"response Parsede:\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5c7fa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response parsed:\n",
      "Cristiano Ronaldo stood at the edge of the pitch, the stadium pulsating with energy. As the final minutes ticked away, his team trailed by a goal. With fierce determination, he sprinted forward, evading defenders like shadows. The ball found his feet, and with a swift movement, he unleashed a powerful shot. Time slowed as the crowd held its breath. The ball soared into the net, igniting a wave of jubilation. Ronaldo’s teammates surrounded him, celebrating a last-minute equalizer. In that moment, he wasn't just a player; he was a symbol of hope, resilience, and pure passion for the game.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with_no_chain(\"Ronaldo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2756010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response Parsede:\n",
      "In a bustling square in Lisbon, a young boy named Miguel dreamed of becoming a football star like his idol, Cristiano Ronaldo. Every day after school, he practiced tirelessly, mimicking Ronaldo's signature moves. One sunny afternoon, Miguel spotted Ronaldo himself passing by. Gathering his courage, he approached and shared his dream. To his astonishment, Ronaldo smiled and invited him to train with him for an hour. They dribbled, shot, and laughed together. Miguel left inspired, not just by the skills learned but also by the kindness shown. That day sparked a lifelong passion, shaping Miguel into a star in his own right.\n"
     ]
    }
   ],
   "source": [
    "using_chain(\"Ronaldo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41d471c",
   "metadata": {},
   "source": [
    "#### Note that using a chain made the code smaller, and more readable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "session-one",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
